name: Deploy LLM Services Only

on:
  push:
    branches:
      - main
      - develop    
    paths:
      - 'llms/**'
      - '.github/workflows/llm-deploy.yml'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io

jobs:
  build-llm-services:
    name: Build LLM Service Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        service:
          - name: ai-service
            context: ./llms/ai
            dockerfile: ./llms/ai/Dockerfile
          - name: gpu-monitor
            context: ./llms/gpu_monitor
            dockerfile: ./llms/gpu_monitor/Dockerfile
          - name: model-initializer
            context: ./llms/initializer
            dockerfile: ./llms/initializer/Dockerfile

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Lowercase repository owner
        run: echo "OWNER_LC=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Sanitize branch name for Docker tag
        run: echo "BRANCH_SAFE=$(echo '${{ github.ref_name }}' | sed 's/\//-/g')" >> $GITHUB_ENV

      - name: Free Disk Space
        if: matrix.service.name == 'ai-service'
        run: |
          echo "=== Before cleanup ==="
          df -h
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          sudo docker image prune -af
          sudo docker system prune -af --volumes
          echo "=== After cleanup ==="
          df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/llm-${{ matrix.service.name }}
          tags: |
            type=raw,value=${{ env.BRANCH_SAFE }}
            type=raw,value=${{ env.BRANCH_SAFE }}-${{ github.sha }}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=${{ matrix.service.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.service.name }}
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  deploy-llm-servers:
    name: Deploy to LLM Servers (1.61 & 1.62)
    runs-on: ubuntu-latest
    needs: [build-llm-services]

    strategy:
      matrix:
        server:
          - host: 192.168.1.61
            name: llm-server-1
          - host: 192.168.1.62
            name: llm-server-2

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Lowercase repository owner
        run: echo "OWNER_LC=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Sanitize branch name for Docker tag
        run: echo "BRANCH_SAFE=$(echo '${{ github.ref_name }}' | sed 's/\//-/g')" >> $GITHUB_ENV

      - name: Setup SSH key for central server
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Test SSH to central server
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 "echo 'Connected to central server'"

      - name: Setup SSH from central to target server
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh-keyscan -H ${{ matrix.server.host }} >> ~/.ssh/known_hosts 2>/dev/null || true"

      - name: Test SSH to target server via central
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh -o StrictHostKeyChecking=no ubuntu@${{ matrix.server.host }} 'echo Connected to ${{ matrix.server.name }}'"

      - name: Create directories on target server
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'mkdir -p ~/llm-deployment ~/models ~/models/huggingface'"

      - name: Copy deployment files via central server
        env:
          SSH_OPTS: "-o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=10 -o StrictHostKeyChecking=no -o TCPKeepAlive=yes -o Compression=yes -c aes128-ctr"
        run: |
          # Create tarball of llms directory (excluding unnecessary files)
          echo "Creating deployment tarball..."
          tar -czf /tmp/llms-deploy.tar.gz -C ./llms \
            --exclude='__pycache__' \
            --exclude='*.pyc' \
            --exclude='.git' \
            --exclude='tests' \
            --exclude='*.md' \
            .

          TARBALL_SIZE=$(du -h /tmp/llms-deploy.tar.gz | cut -f1)
          echo "✓ Tarball created: $TARBALL_SIZE"

          # Copy tarball to central server with retry logic and network optimizations
          echo "Copying tarball to central server (using fast cipher, compression, and aggressive keep-alive)..."
          MAX_RETRIES=3
          RETRY_COUNT=0
          SCP_SUCCESS=false

          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SCP_SUCCESS" = "false" ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              WAIT_TIME=$((2 ** RETRY_COUNT))
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting ${WAIT_TIME}s..."
              sleep $WAIT_TIME
            fi

            # Use optimized transfer: fast cipher (aes128-ctr), SSH compression, aggressive keep-alive, 10min timeout
            if timeout 600 scp -v -P 2324 $SSH_OPTS -i ~/.ssh/deploy_key \
              /tmp/llms-deploy.tar.gz ${{ secrets.SSH_USER }}@217.219.39.212:/tmp/llms-deploy.tar.gz; then
              echo "✓ Copied to central server"
              SCP_SUCCESS=true
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ SCP to central failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          if [ "$SCP_SUCCESS" = "false" ]; then
            echo "ERROR: Failed to copy tarball to central server after $MAX_RETRIES attempts"
            rm /tmp/llms-deploy.tar.gz
            exit 1
          fi

          # Extract on target server via central server with timeouts
          echo "Deploying to target server ${{ matrix.server.host }}..."
          timeout 500 ssh -p 2324 $SSH_OPTS -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "timeout 400 scp -v \
              -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=10 \
              -o TCPKeepAlive=yes -o Compression=yes -c aes128-ctr \
              /tmp/llms-deploy.tar.gz ubuntu@${{ matrix.server.host }}:/tmp/llms-deploy.tar.gz && \
            timeout 90 ssh -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              ubuntu@${{ matrix.server.host }} 'cd ~/llm-deployment && tar -xzf /tmp/llms-deploy.tar.gz && rm /tmp/llms-deploy.tar.gz' && \
            rm /tmp/llms-deploy.tar.gz && \
            echo '✓ Deployment files transferred successfully'"

          # Clean up local
          rm /tmp/llms-deploy.tar.gz
          echo "✓ Local cleanup complete"

      - name: Create .env file on target server
        env:
          OWNER_LC: ${{ env.OWNER_LC }}
          BRANCH_SAFE: ${{ env.BRANCH_SAFE }}
          IMAGE_TAG: ${{ env.BRANCH_SAFE }}-${{ github.sha }}
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            echo GITHUB_REGISTRY=${{ env.REGISTRY }} > .env && \
            echo GITHUB_REPOSITORY_OWNER=${{ env.OWNER_LC }} >> .env && \
            echo IMAGE_TAG=${{ env.BRANCH_SAFE }}-${{ github.sha }} >> .env && \
            echo MODEL_CACHE_PATH=/home/ubuntu/models >> .env\"'"

      - name: Verify .env file
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"echo === Environment File === && cat ~/llm-deployment/.env\"'"

      - name: Login to GHCR on target server
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} \"echo '${{ secrets.GHCR_TOKEN }}' | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin\""

      - name: Stop running containers
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && docker compose down || true\"'"

      - name: Clean up old images
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'docker image prune -f || true'"

      - name: Pull latest images
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && docker compose pull\"'"

      - name: Start services (smart deployment)
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            if [ -f /home/ubuntu/models/.init_complete ]; then \
              echo Models already present, starting all services...; \
              docker compose up -d; \
            else \
              echo Models not found, starting initializer in background...; \
              docker compose up -d model_initializer; \
              echo Initializer started - will take 30-60 minutes for first download; \
              echo Once complete, re-run deployment to start AI service; \
            fi\"'"

      - name: Check model initializer status
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            if docker ps --format {{.Names}} | grep -q model_initializer; then \
              echo ⏳ Model initializer is running...; \
              echo Monitor with: docker logs -f model_initializer; \
            elif docker ps -a --format {{.Names}} | grep -q model_initializer; then \
              EXIT_CODE=\\\$(docker inspect model_initializer --format={{.State.ExitCode}} 2>/dev/null || echo 999); \
              if [ \\\$EXIT_CODE -eq 0 ]; then \
                echo ✓ Model initializer completed successfully; \
              else \
                echo ✗ Model initializer failed with exit code \\\$EXIT_CODE; \
                docker logs model_initializer --tail=50; \
              fi; \
            else \
              echo ℹ Model initializer has not run yet; \
            fi\"'"

      - name: Wait for AI service to be healthy (if started)
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            if docker ps --format {{.Names}} | grep -q ai_service; then \
              echo Waiting for AI service to be healthy...; \
              timeout 300 bash -c \\\"until docker compose ps | grep -q healthy; do sleep 10; echo Still waiting...; done\\\" && echo ✓ Services are healthy || echo ⚠ Health check timed out; \
            else \
              echo ℹ AI service not started yet - waiting for model download to complete; \
            fi\"'"

      - name: Show service status
        continue-on-error: true
        timeout-minutes: 3
        run: |
          # Add retry logic for SSH connection
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 5s..."
              sleep 5
            fi

            if timeout 120 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
              "timeout 60 ssh -o ConnectTimeout=20 ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
              echo === Docker Compose Status === && \
              docker compose ps && \
              echo && \
              echo === Deployment Summary === && \
              if [ -f /home/ubuntu/models/.init_complete ]; then \
                echo ✓ Models: Downloaded; \
              else \
                echo ⏳ Models: Downloading in background; \
              fi && \
              if docker ps --format {{.Names}} | grep -q ai_service; then \
                echo ✓ AI Service: Running; \
              else \
                echo ⏳ AI Service: Waiting for models; \
              fi\"'"; then
              echo "✓ Status check successful"
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ Status check failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          echo "⚠ Status check failed after $MAX_RETRIES attempts (non-critical)"
          exit 0

      - name: Check GPU availability
        continue-on-error: true
        timeout-minutes: 2
        run: |
          # Add retry logic for SSH connection
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 5s..."
              sleep 5
            fi

            if timeout 90 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
              "timeout 30 ssh -o ConnectTimeout=20 ubuntu@${{ matrix.server.host }} 'nvidia-smi || echo nvidia-smi not available'"; then
              echo "✓ GPU check successful"
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ GPU check failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          echo "⚠ GPU check failed after $MAX_RETRIES attempts (non-critical)"
          exit 0

      - name: Show logs on failure
        if: failure()
        continue-on-error: true
        timeout-minutes: 3
        run: |
          # Try to fetch logs with retry logic
          MAX_RETRIES=2
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 5s..."
              sleep 5
            fi

            if timeout 150 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
              "timeout 120 ssh -o ConnectTimeout=20 ubuntu@${{ matrix.server.host }} 'cd ~/llm-deployment && \
              echo \"=== Docker Compose Status ===\" && docker compose ps -a && \
              echo \"=== Initializer Logs ===\" && docker logs model_initializer --tail=100 2>/dev/null || echo \"model_initializer not found\" && \
              echo \"=== AI Service Logs ===\" && docker logs ai_service --tail=100 2>/dev/null || echo \"ai_service not found\" && \
              echo \"=== GPU Monitor Logs ===\" && docker logs gpu_monitor --tail=50 2>/dev/null || echo \"gpu_monitor not found\" && \
              echo \"=== Nginx Logs ===\" && docker logs nginx_ai --tail=50 2>/dev/null || echo \"nginx_ai not found\"'"; then
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
            fi
          done

          echo "⚠ Could not fetch logs (SSH connection issue)"
          exit 0


  health-check:
    name: LLM Services Health Check
    runs-on: ubuntu-latest
    needs: [deploy-llm-servers]

    steps:
      - name: Sanitize branch name for display
        run: echo "BRANCH_SAFE=$(echo '${{ github.ref_name }}' | sed 's/\//-/g')" >> $GITHUB_ENV

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Health check from central server
        continue-on-error: true
        timeout-minutes: 3
        env:
          IMAGE_TAG: ${{ env.BRANCH_SAFE }}-${{ github.sha }}
        run: |
          # Add retry logic for SSH connection
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 10s..."
              sleep 10
            fi

            if timeout 120 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << ENDSSH
          echo "================================"
          echo "LLM Services Health Check"
          echo "================================"
          sleep 10

          echo "Checking LLM Server 1.61..."
          if curl -f -s --max-time 15 http://192.168.1.61/health; then
            echo "✓ Server 1.61 is healthy"
          else
            echo "⚠ Warning: Server 1.61 health check failed"
          fi

          echo ""
          echo "Checking LLM Server 1.62..."
          if curl -f -s --max-time 15 http://192.168.1.62/health; then
            echo "✓ Server 1.62 is healthy"
          else
            echo "⚠ Warning: Server 1.62 health check failed"
          fi

          echo ""
          echo "================================"
          echo "Deployment Summary"
          echo "================================"
          echo "LLM Server 1: http://192.168.1.61"
          echo "LLM Server 2: http://192.168.1.62"
          echo "Image Tag: $IMAGE_TAG"
          echo "================================"
          ENDSSH
            then
              echo "✓ Health check completed successfully"
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ Health check failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          echo "⚠ Health check failed after $MAX_RETRIES attempts (non-critical)"
          exit 0