name: Deploy LLM Services Only

on:
  push:
    branches:
      - main
      - develop    
    paths:
      - 'llms/**'
      - '.github/workflows/llm-deploy.yml'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io

jobs:
  build-llm-services:
    name: Build LLM Service Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        service:
          - name: ai-service
            context: ./llms/ai
            dockerfile: ./llms/ai/Dockerfile
          - name: gpu-monitor
            context: ./llms/gpu_monitor
            dockerfile: ./llms/gpu_monitor/Dockerfile
          - name: model-initializer
            context: ./llms/initializer
            dockerfile: ./llms/initializer/Dockerfile

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Lowercase repository owner
        run: echo "OWNER_LC=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Sanitize branch name for Docker tag
        run: echo "BRANCH_SAFE=$(echo '${{ github.ref_name }}' | sed 's/\//-/g')" >> $GITHUB_ENV

      - name: Free Disk Space
        if: matrix.service.name == 'ai-service'
        run: |
          echo "=== Before cleanup ==="
          df -h
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          sudo docker image prune -af
          sudo docker system prune -af --volumes
          echo "=== After cleanup ==="
          df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.OWNER_LC }}/llm-${{ matrix.service.name }}
          tags: |
            type=raw,value=${{ env.BRANCH_SAFE }}
            type=raw,value=${{ env.BRANCH_SAFE }}-${{ github.sha }}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=${{ matrix.service.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.service.name }}
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  deploy-llm-servers:
    name: Deploy to LLM Servers (1.61 & 1.62)
    runs-on: ubuntu-latest
    needs: [build-llm-services]

    strategy:
      matrix:
        server:
          - host: 192.168.1.61
            name: llm-server-1
          - host: 192.168.1.62
            name: llm-server-2

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Lowercase repository owner
        run: echo "OWNER_LC=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Sanitize branch name for Docker tag
        run: echo "BRANCH_SAFE=$(echo '${{ github.ref_name }}' | sed 's/\//-/g')" >> $GITHUB_ENV

      - name: Setup SSH key for central server
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Deploy files via central server
        run: |
          # Simple SSH streaming approach - minimal connections
          echo "Deploying to ${{ matrix.server.host }}..."

          # Stream tarball directly to central, then to target in one step
          tar -czf - -C ./llms \
            --exclude='__pycache__' \
            --exclude='*.pyc' \
            --exclude='.git' \
            --exclude='tests' \
            --exclude='*.md' \
            . | ssh -p 2324 \
            -o ConnectTimeout=60 \
            -o ServerAliveInterval=30 \
            -o ServerAliveCountMax=5 \
            -o StrictHostKeyChecking=no \
            -o Compression=yes \
            -i ~/.ssh/deploy_key \
            ${{ secrets.SSH_USER }}@217.219.39.212 \
            "cat > /tmp/deploy-${{ matrix.server.name }}.tar.gz && \
             scp -o StrictHostKeyChecking=no /tmp/deploy-${{ matrix.server.name }}.tar.gz ubuntu@${{ matrix.server.host }}:/tmp/llms-deploy.tar.gz && \
             ssh -o StrictHostKeyChecking=no ubuntu@${{ matrix.server.host }} 'mkdir -p ~/llm-deployment ~/models ~/models/huggingface && cd ~/llm-deployment && tar -xzf /tmp/llms-deploy.tar.gz && rm -f /tmp/llms-deploy.tar.gz' && \
             rm -f /tmp/deploy-${{ matrix.server.name }}.tar.gz"

          echo "✓ Deployment complete"

      - name: Create .env file on target server
        env:
          OWNER_LC: ${{ env.OWNER_LC }}
          BRANCH_SAFE: ${{ env.BRANCH_SAFE }}
          IMAGE_TAG: ${{ env.BRANCH_SAFE }}-${{ github.sha }}
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            echo GITHUB_REGISTRY=${{ env.REGISTRY }} > .env && \
            echo GITHUB_REPOSITORY_OWNER=${{ env.OWNER_LC }} >> .env && \
            echo IMAGE_TAG=${{ env.BRANCH_SAFE }}-${{ github.sha }} >> .env && \
            echo MODEL_CACHE_PATH=/home/ubuntu/models >> .env\"'"

      - name: Verify .env file
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"echo === Environment File === && cat ~/llm-deployment/.env\"'"

      - name: Login to GHCR on target server
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} \"echo '${{ secrets.GHCR_TOKEN }}' | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin\""

      - name: Stop running containers
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && docker compose down || true\"'"

      - name: Clean up old images
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'docker image prune -f || true'"

      - name: Pull latest images
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && docker compose pull\"'"

      - name: Start services (smart deployment)
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            if [ -f /home/ubuntu/models/.init_complete ]; then \
              echo Models already present, starting all services...; \
              docker compose up -d; \
            else \
              echo Models not found, starting initializer in background...; \
              docker compose up -d model_initializer; \
              echo Initializer started - will take 30-60 minutes for first download; \
              echo Once complete, re-run deployment to start AI service; \
            fi\"'"

      - name: Check model initializer status
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            if docker ps --format {{.Names}} | grep -q model_initializer; then \
              echo ⏳ Model initializer is running...; \
              echo Monitor with: docker logs -f model_initializer; \
            elif docker ps -a --format {{.Names}} | grep -q model_initializer; then \
              EXIT_CODE=\\\$(docker inspect model_initializer --format={{.State.ExitCode}} 2>/dev/null || echo 999); \
              if [ \\\$EXIT_CODE -eq 0 ]; then \
                echo ✓ Model initializer completed successfully; \
              else \
                echo ✗ Model initializer failed with exit code \\\$EXIT_CODE; \
                docker logs model_initializer --tail=50; \
              fi; \
            else \
              echo ℹ Model initializer has not run yet; \
            fi\"'"

      - name: Wait for AI service to be healthy (if started)
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
            "ssh ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
            if docker ps --format {{.Names}} | grep -q ai_service; then \
              echo Waiting for AI service to be healthy...; \
              timeout 300 bash -c \\\"until docker compose ps | grep -q healthy; do sleep 10; echo Still waiting...; done\\\" && echo ✓ Services are healthy || echo ⚠ Health check timed out; \
            else \
              echo ℹ AI service not started yet - waiting for model download to complete; \
            fi\"'"

      - name: Show service status
        continue-on-error: true
        timeout-minutes: 3
        run: |
          # Add retry logic for SSH connection
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 5s..."
              sleep 5
            fi

            if timeout 120 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
              "timeout 60 ssh -o ConnectTimeout=20 ubuntu@${{ matrix.server.host }} 'bash -c \"cd ~/llm-deployment && \
              echo === Docker Compose Status === && \
              docker compose ps && \
              echo && \
              echo === Deployment Summary === && \
              if [ -f /home/ubuntu/models/.init_complete ]; then \
                echo ✓ Models: Downloaded; \
              else \
                echo ⏳ Models: Downloading in background; \
              fi && \
              if docker ps --format {{.Names}} | grep -q ai_service; then \
                echo ✓ AI Service: Running; \
              else \
                echo ⏳ AI Service: Waiting for models; \
              fi\"'"; then
              echo "✓ Status check successful"
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ Status check failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          echo "⚠ Status check failed after $MAX_RETRIES attempts (non-critical)"
          exit 0

      - name: Check GPU availability
        continue-on-error: true
        timeout-minutes: 2
        run: |
          # Add retry logic for SSH connection
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 5s..."
              sleep 5
            fi

            if timeout 90 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
              "timeout 30 ssh -o ConnectTimeout=20 ubuntu@${{ matrix.server.host }} 'nvidia-smi || echo nvidia-smi not available'"; then
              echo "✓ GPU check successful"
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ GPU check failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          echo "⚠ GPU check failed after $MAX_RETRIES attempts (non-critical)"
          exit 0

      - name: Show logs on failure
        if: failure()
        continue-on-error: true
        timeout-minutes: 3
        run: |
          # Try to fetch logs with retry logic
          MAX_RETRIES=2
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 5s..."
              sleep 5
            fi

            if timeout 150 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 \
              "timeout 120 ssh -o ConnectTimeout=20 ubuntu@${{ matrix.server.host }} 'cd ~/llm-deployment && \
              echo \"=== Docker Compose Status ===\" && docker compose ps -a && \
              echo \"=== Initializer Logs ===\" && docker logs model_initializer --tail=100 2>/dev/null || echo \"model_initializer not found\" && \
              echo \"=== AI Service Logs ===\" && docker logs ai_service --tail=100 2>/dev/null || echo \"ai_service not found\" && \
              echo \"=== GPU Monitor Logs ===\" && docker logs gpu_monitor --tail=50 2>/dev/null || echo \"gpu_monitor not found\" && \
              echo \"=== Nginx Logs ===\" && docker logs nginx_ai --tail=50 2>/dev/null || echo \"nginx_ai not found\"'"; then
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
            fi
          done

          echo "⚠ Could not fetch logs (SSH connection issue)"
          exit 0


  health-check:
    name: LLM Services Health Check
    runs-on: ubuntu-latest
    needs: [deploy-llm-servers]

    steps:
      - name: Sanitize branch name for display
        run: echo "BRANCH_SAFE=$(echo '${{ github.ref_name }}' | sed 's/\//-/g')" >> $GITHUB_ENV

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Health check from central server
        continue-on-error: true
        timeout-minutes: 3
        env:
          IMAGE_TAG: ${{ env.BRANCH_SAFE }}-${{ github.sha }}
        run: |
          # Add retry logic for SSH connection
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "Retry $RETRY_COUNT/$MAX_RETRIES - waiting 10s..."
              sleep 10
            fi

            if timeout 120 ssh -p 2324 -o ConnectTimeout=30 -o ServerAliveInterval=15 \
              -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << ENDSSH
          echo "================================"
          echo "LLM Services Health Check"
          echo "================================"
          sleep 10

          echo "Checking LLM Server 1.61..."
          if curl -f -s --max-time 15 http://192.168.1.61/health; then
            echo "✓ Server 1.61 is healthy"
          else
            echo "⚠ Warning: Server 1.61 health check failed"
          fi

          echo ""
          echo "Checking LLM Server 1.62..."
          if curl -f -s --max-time 15 http://192.168.1.62/health; then
            echo "✓ Server 1.62 is healthy"
          else
            echo "⚠ Warning: Server 1.62 health check failed"
          fi

          echo ""
          echo "================================"
          echo "Deployment Summary"
          echo "================================"
          echo "LLM Server 1: http://192.168.1.61"
          echo "LLM Server 2: http://192.168.1.62"
          echo "Image Tag: $IMAGE_TAG"
          echo "================================"
          ENDSSH
            then
              echo "✓ Health check completed successfully"
              exit 0
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "✗ Health check failed (attempt $RETRY_COUNT/$MAX_RETRIES)"
            fi
          done

          echo "⚠ Health check failed after $MAX_RETRIES attempts (non-critical)"
          exit 0