name: Deploy LLM Services Only

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'llms/**'
      - '.github/workflows/deploy-llm.yml'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}

jobs:
  build-llm-services:
    name: Build LLM Service Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        service:
          - name: ai-service
            context: ./llms/ai
            dockerfile: ./llms/ai/Dockerfile
          - name: gpu-monitor
            context: ./llms/gpu_monitor
            dockerfile: ./llms/gpu_monitor/Dockerfile
          - name: model-initializer
            context: ./llms/initializer
            dockerfile: ./llms/initializer/Dockerfile

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Free Disk Space (only for large ai-service build)
        if: matrix.service.name == 'ai-service'
        run: |
          echo "=== Before cleanup ==="
          df -h
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          sudo docker image prune -af
          sudo docker system prune -af --volumes
          echo "=== After cleanup ==="
          df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/llm-${{ matrix.service.name }}
          tags: |
            type=ref,event=branch
            type=sha,format=long,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=${{ matrix.service.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.service.name }}
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  deploy-llm-servers:
    name: Deploy to LLM Servers (1.61 & 1.62)
    runs-on: ubuntu-latest
    needs: [build-llm-services]

    strategy:
      matrix:
        server:
          - host: 192.168.1.61
            name: llm-server-1
          - host: 192.168.1.62
            name: llm-server-2

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup SSH key for central server
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Deploy to ${{ matrix.server.name }} via central server
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << 'ENDSSH'
          set -euo pipefail

          echo "==================================================================="
          echo "Deploying to ${{ matrix.server.name }} (${{ matrix.server.host }})"
          echo "==================================================================="

          # Test SSH to target server
          echo "=== Testing SSH connection ==="
          if ! ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@${{ matrix.server.host }} "echo 'SSH OK'"; then
            echo "❌ ERROR: Cannot SSH to ${{ matrix.server.host }}"
            exit 1
          fi
          echo "✓ SSH connection successful"

          # Prepare directories
          echo ""
          echo "=== Preparing directories ==="
          ssh ubuntu@${{ matrix.server.host }} "mkdir -p ~/llm-deployment ~/models/huggingface"
          echo "✓ Directories created"

          # Clone repo temporarily on central server
          echo ""
          echo "=== Cloning repository ==="
          cd /tmp
          rm -rf llm-deploy-temp
          if ! git clone --depth 1 --branch ${{ github.ref_name }} https://github.com/${{ github.repository }}.git llm-deploy-temp; then
            echo "❌ ERROR: Failed to clone repository"
            exit 1
          fi
          echo "✓ Repository cloned"

          # Verify critical files exist in repo
          echo ""
          echo "=== Verifying repository files ==="
          if [ ! -f /tmp/llm-deploy-temp/llms/docker-compose.yml ]; then
            echo "❌ ERROR: docker-compose.yml not found in llms/"
            ls -la /tmp/llm-deploy-temp/llms/
            exit 1
          fi
          if [ ! -f /tmp/llm-deploy-temp/llms/nginx_configs/nginx.conf ]; then
            echo "❌ ERROR: nginx.conf not found"
            exit 1
          fi
          if [ ! -f /tmp/llm-deploy-temp/llms/nginx_configs/conf.d/default.conf ]; then
            echo "❌ ERROR: nginx default.conf not found"
            exit 1
          fi
          echo "✓ All required files present in repository"

          # Copy deployment files
          echo ""
          echo "=== Copying deployment files to target ==="
          if ! scp -r /tmp/llm-deploy-temp/llms/* ubuntu@${{ matrix.server.host }}:~/llm-deployment/; then
            echo "❌ ERROR: Failed to copy files to target server"
            exit 1
          fi
          echo "✓ Files copied successfully"

          # Verify files were copied correctly
          echo ""
          echo "=== Verifying files on target server ==="
          ssh ubuntu@${{ matrix.server.host }} "
            cd ~/llm-deployment
            
            [ -f docker-compose.yml ] || { echo '❌ docker-compose.yml missing'; exit 1; }
            [ -f nginx_configs/nginx.conf ] || { echo '❌ nginx.conf missing'; exit 1; }
            [ -f nginx_configs/conf.d/default.conf ] || { echo '❌ default.conf missing'; exit 1; }
            
            echo '✓ docker-compose.yml present'
            echo '✓ nginx.conf present'
            echo '✓ default.conf present'
            
            echo ''
            echo 'Deployment directory structure:'
            ls -la
            echo ''
            echo 'Nginx configs:'
            ls -la nginx_configs/conf.d/
          "

          # Create .env with exact tag
          echo ""
          echo "=== Creating .env file ==="
          ssh ubuntu@${{ matrix.server.host }} << 'ENVEOF'
          cat > ~/llm-deployment/.env << EOF
GITHUB_REGISTRY=${{ env.REGISTRY }}
GITHUB_REPOSITORY_OWNER=${{ env.IMAGE_PREFIX }}
IMAGE_TAG=${{ github.ref_name }}-${{ github.sha }}
MODEL_CACHE_PATH=/home/ubuntu/models/huggingface
EOF
ENVEOF

          ssh ubuntu@${{ matrix.server.host }} "cat ~/llm-deployment/.env"
          echo "✓ .env file created"

          # Docker login
          echo ""
          echo "=== Logging into GitHub Container Registry ==="
          if ! ssh ubuntu@${{ matrix.server.host }} "echo '${{ secrets.GITHUB_TOKEN }}' | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin 2>&1 | grep -v 'WARNING'"; then
            echo "❌ ERROR: Docker login failed"
            exit 1
          fi
          echo "✓ Docker login successful"

          # Stop old containers
          echo ""
          echo "=== Stopping old services ==="
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose down 2>&1" || true
          echo "✓ Old services stopped"

          # Clean up old images
          echo ""
          echo "=== Cleaning up old images ==="
          ssh ubuntu@${{ matrix.server.host }} "docker image prune -f 2>&1 | head -5"

          # Pull new images
          echo ""
          echo "=== Pulling images (tag: ${{ github.ref_name }}-${{ github.sha }}) ==="
          if ! ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose pull 2>&1"; then
            echo "❌ ERROR: Failed to pull images"
            echo ""
            echo "Current images on server:"
            ssh ubuntu@${{ matrix.server.host }} "docker images | grep -E 'REPOSITORY|llm-'"
            exit 1
          fi
          echo "✓ Images pulled successfully"

          # Verify all required images are present
          echo ""
          echo "=== Verifying images ==="
          ssh ubuntu@${{ matrix.server.host }} "
            echo 'Checking for required images...'
            missing=0
            
            if docker images | grep -q 'llm-ai-service.*${{ github.ref_name }}-${{ github.sha }}'; then
              echo '✓ llm-ai-service found'
            else
              echo '❌ llm-ai-service NOT found'
              missing=1
            fi
            
            if docker images | grep -q 'llm-gpu-monitor.*${{ github.ref_name }}-${{ github.sha }}'; then
              echo '✓ llm-gpu-monitor found'
            else
              echo '❌ llm-gpu-monitor NOT found'
              missing=1
            fi
            
            if docker images | grep -q 'llm-model-initializer.*${{ github.ref_name }}-${{ github.sha }}'; then
              echo '✓ llm-model-initializer found'
            else
              echo '❌ llm-model-initializer NOT found'
              missing=1
            fi
            
            if [ \$missing -eq 1 ]; then
              echo ''
              echo 'Available llm images:'
              docker images | grep llm-
              exit 1
            fi
            
            echo ''
            echo '✓ All required images present'
          "

          # Start services
          echo ""
          echo "=== Starting services ==="
          if ! ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose up -d 2>&1"; then
            echo "❌ ERROR: Failed to start services"
            ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose logs --tail 50"
            exit 1
          fi
          echo "✓ Services started"

          # Show initial status
          echo ""
          echo "=== Initial container status ==="
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose ps"

          # Wait for model_initializer
          echo ""
          echo "=== Waiting for model_initializer to complete ==="
          ssh ubuntu@${{ matrix.server.host }} "
            timeout 1800 bash -c '
              while docker ps -a --format \"{{.Name}}\" | grep -q model_initializer; do
                status=\$(docker inspect --format=\"{{.State.Status}}\" model_initializer 2>/dev/null || echo \"missing\")
                
                if [ "\$status" = "missing" ]; then
                  echo "❌ ERROR: model_initializer container disappeared"
                  exit 1
                fi
                
                if [ "\$status" = "exited" ]; then
                  code=\$(docker inspect --format=\"{{.State.ExitCode}}\" model_initializer)
                  if [ "\$code" = "0" ]; then
                    echo "✓ model_initializer completed successfully (exit code 0)"
                    break
                  else
                    echo "❌ ERROR: model_initializer failed with exit code \$code"
                    echo ""
                    echo "Last 100 lines of logs:"
                    docker logs model_initializer --tail 100
                    exit 1
                  fi
                fi
                
                if [ "\$status" = "running" ]; then
                  echo "⏳ model_initializer still running..."
                  docker logs model_initializer --tail 3 2>&1 | grep -v \"^$\" || true
                fi
                
                sleep 10
              done
            '
          "
          if [ $? -ne 0 ]; then
            echo "❌ model_initializer failed or timed out"
            exit 1
          fi

          # Wait for ai_service healthy
          echo ""
          echo "=== Waiting for ai_service to become healthy ==="
          ssh ubuntu@${{ matrix.server.host }} "
            cd ~/llm-deployment
            timeout 600 bash -c '
              attempt=1
              max_attempts=60
              
              while [ \$attempt -le \$max_attempts ]; do
                status=\$(docker compose ps ai_service 2>&1)
                
                if echo "\$status" | grep -q "healthy"; then
                  echo "✓ ai_service is healthy!"
                  break
                fi
                
                if echo "\$status" | grep -qE "Exit|Exited"; then
                  echo "❌ ERROR: ai_service exited unexpectedly"
                  docker compose logs ai_service --tail 50
                  exit 1
                fi
                
                if [ \$attempt -eq 1 ] || [ \$((attempt % 6)) -eq 0 ]; then
                  echo "⏳ Attempt \$attempt/\$max_attempts: Waiting for ai_service to be healthy..."
                  docker compose ps ai_service | grep ai_service || true
                  docker logs ai_service --tail 5 2>&1 | grep -v \"^$\" || true
                fi
                
                sleep 10
                attempt=\$((attempt + 1))
              done
              
              if [ \$attempt -gt \$max_attempts ]; then
                echo "❌ ERROR: ai_service failed to become healthy after \$max_attempts attempts"
                echo ""
                echo "Container status:"
                docker compose ps ai_service
                echo ""
                echo "Recent logs:"
                docker compose logs ai_service --tail 100
                exit 1
              fi
            '
          "
          if [ $? -ne 0 ]; then
            echo "❌ ai_service health check failed or timed out"
            exit 1
          fi

          # Final status
          echo ""
          echo "=== Final container status ==="
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose ps"

          # Verify GPU access
          echo ""
          echo "=== GPU status ==="
          if ssh ubuntu@${{ matrix.server.host }} "nvidia-smi 2>&1 | head -20"; then
            echo "✓ GPU accessible"
          else
            echo "⚠️  WARNING: nvidia-smi failed - GPU may not be accessible to containers"
          fi

          # Test health endpoint
          echo ""
          echo "=== Testing health endpoint ==="
          sleep 5
          if ssh ubuntu@${{ matrix.server.host }} "curl -f -s --max-time 10 http://localhost/health"; then
            echo ""
            echo "✓ Health endpoint responding"
          else
            echo ""
            echo "⚠️  WARNING: Health endpoint not responding yet (may need more time)"
          fi

          # Cleanup
          rm -rf /tmp/llm-deploy-temp
          
          echo ""
          echo "==================================================================="
          echo "✓✓✓ DEPLOYMENT COMPLETED SUCCESSFULLY ✓✓✓"
          echo "Server: ${{ matrix.server.name }} (${{ matrix.server.host }})"
          echo "Tag: ${{ github.ref_name }}-${{ github.sha }}"
          echo "==================================================================="
          ENDSSH

      - name: Show detailed logs on failure
        if: failure()
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << 'ENDSSH'
          echo ""
          echo "==================================================================="
          echo "FAILURE DIAGNOSTICS FOR ${{ matrix.server.host }}"
          echo "==================================================================="
          
          ssh ubuntu@${{ matrix.server.host }} "
            cd ~/llm-deployment 2>/dev/null || { echo 'Deployment directory does not exist'; exit 0; }
            
            echo ''
            echo '=== Container Status ==='
            docker compose ps -a
            
            echo ''
            echo '=== Docker Images ==='
            docker images | grep -E 'REPOSITORY|llm-'
            
            echo ''
            echo '=== .env File ==='
            cat .env 2>/dev/null || echo '.env not found'
            
            echo ''
            echo '=== Disk Space ==='
            df -h /
            df -h ~/models 2>/dev/null || true
            
            echo ''
            echo '=== model_initializer logs (last 150 lines) ==='
            docker logs model_initializer --tail 150 2>/dev/null || echo 'Container not found'
            
            echo ''
            echo '=== ai_service logs (last 150 lines) ==='
            docker logs ai_service --tail 150 2>/dev/null || echo 'Container not found'
            
            echo ''
            echo '=== nginx logs (last 100 lines) ==='
            docker logs nginx_ai --tail 100 2>/dev/null || echo 'Container not found'
            
            echo ''
            echo '=== gpu_monitor logs (last 50 lines) ==='
            docker logs gpu_monitor --tail 50 2>/dev/null || echo 'Container not found'
            
            echo ''
            echo '=== GPU Status ==='
            nvidia-smi 2>&1 | head -20 || echo 'nvidia-smi failed'
            
            echo ''
            echo '=== Network Status ==='
            docker network ls
            docker network inspect ai_network 2>/dev/null || echo 'ai_network not found'
            
            echo ''
            echo '==================================================================='
          "
          ENDSSH

  health-check:
    name: LLM Services Health Check
    runs-on: ubuntu-latest
    needs: [deploy-llm-servers]

    steps:
      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Perform health checks
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << 'ENDSSH'
          set -euo pipefail

          echo "==================================================================="
          echo "LLM Services Health Check"
          echo "==================================================================="

          # Give services a moment to fully stabilize
          echo "Waiting 10 seconds for services to stabilize..."
          sleep 10

          echo ""
          echo "=== Checking Server 1 (192.168.1.61) ==="
          if response=$(curl -f -s --max-time 15 http://192.168.1.61/health 2>&1); then
            echo "✓ Server 1 health check PASSED"
            echo "Response: $response"
          else
            echo "❌ Server 1 health check FAILED"
            echo "Response: $response"
            exit 1
          fi

          echo ""
          echo "=== Checking Server 2 (192.168.1.62) ==="
          if response=$(curl -f -s --max-time 15 http://192.168.1.62/health 2>&1); then
            echo "✓ Server 2 health check PASSED"
            echo "Response: $response"
          else
            echo "❌ Server 2 health check FAILED"
            echo "Response: $response"
            exit 1
          fi

          echo ""
          echo "==================================================================="
          echo "✓✓✓ ALL SERVICES ARE HEALTHY AND OPERATIONAL ✓✓✓"
          echo ""
          echo "Server 1: http://192.168.1.61"
          echo "Server 2: http://192.168.1.62"
          echo ""
          echo "Deployed Image Tag: ${{ github.ref_name }}-${{ github.sha }}"
          echo "==================================================================="
          ENDSSH