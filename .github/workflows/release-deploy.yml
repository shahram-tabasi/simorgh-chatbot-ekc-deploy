name: Release Deploy Multi-Server

on:
  release:
    types: [published, created]
  push:
    tags:
      - 'v*'
      - 'release-*'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}

jobs:
  build-simorgh-agent:
    name: Build Simorgh Agent Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    strategy:
      matrix:
        service:
          - name: backend-flask
            context: ./simorgh-agent/flask
            dockerfile: ./simorgh-agent/flask/Dockerfile
          - name: cable-api
            context: ./simorgh-agent/cable_api
            dockerfile: ./simorgh-agent/cable_api/Dockerfile
          - name: frontend
            context: ./simorgh-agent/react
            dockerfile: ./simorgh-agent/react/Dockerfile
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/simorgh-${{ matrix.service.name }}
          tags: |
            type=ref,event=tag
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=raw,value=latest

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=${{ matrix.service.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.service.name }}

  build-llm-services:
    name: Build LLM Service Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    strategy:
      matrix:
        service:
          - name: ai-service
            context: ./llms/ai
            dockerfile: ./llms/ai/Dockerfile
          - name: gpu-monitor
            context: ./llms/gpu_monitor
            dockerfile: ./llms/gpu_monitor/Dockerfile
          - name: model-initializer
            context: ./llms/initializer
            dockerfile: ./llms/initializer/Dockerfile
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Free Disk Space
        if: matrix.service.name == 'ai-service'
        run: |
          echo "=== Before cleanup ==="
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune -af
          sudo docker system prune -af --volumes
          echo "=== After cleanup ==="
          df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/llm-${{ matrix.service.name }}
          tags: |
            type=ref,event=tag
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=raw,value=latest

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=${{ matrix.service.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.service.name }}
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  deploy-central-server:
    name: Deploy to Central Server (1.68)
    runs-on: ubuntu-latest
    needs: [build-simorgh-agent]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get tag name
        id: tag
        run: echo "tag=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT

      - name: Lowercase repository owner
        id: lowercase
        run: |
          OWNER_LC=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')
          echo "OWNER_LC=$OWNER_LC" >> $GITHUB_ENV
          echo "Repository owner (lowercase): $OWNER_LC"

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Copy deployment files to server
        run: |
          scp -P 2324 -i ~/.ssh/deploy_key -r simorgh-agent/* ${{ secrets.SSH_USER }}@217.219.39.212:~/simorgh-deployment/

      - name: Create .env file and deploy
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << 'ENDSSH'
          cd ~/simorgh-deployment

          # Login to GitHub Container Registry
          echo "${{ secrets.GHCR_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

          # Create .env file
          cat > .env << EOF
          # GitHub Registry
          GITHUB_REPOSITORY_OWNER=${{ env.OWNER_LC }}
          IMAGE_TAG=${{ steps.tag.outputs.tag }}

          # Neo4j
          NEO4J_URI=bolt://neo4j:7687
          NEO4J_USER=neo4j
          NEO4J_PASSWORD=${{ secrets.NEO4J_PASSWORD }}

          # Redis
          REDIS_URL=redis://redis:6379/0
          REDIS_CHAT_DB=1
          REDIS_CACHE_DB=2
          REDIS_AUTH_DB=3

          # Qdrant
          QDRANT_URL=http://qdrant:6333

          # CocoIndex
          COCOINDEX_URL=http://cocoindex:8080
          COCOINDEX_DB_PASSWORD=${{ secrets.COCOINDEX_DB_PASSWORD }}

          # MySQL (External Authentication)
          MYSQL_HOST=${{ secrets.MYSQL_HOST }}
          MYSQL_PORT=${{ secrets.MYSQL_PORT }}
          MYSQL_USER=${{ secrets.MYSQL_USER }}
          MYSQL_PASSWORD=${{ secrets.MYSQL_PASSWORD }}
          MYSQL_DATABASE=${{ secrets.MYSQL_DATABASE }}
          SQL_SERVER_HOST=${{ secrets.MYSQL_HOST }}
          SQL_SERVER_PORT=${{ secrets.MYSQL_PORT }}
          SQL_SERVER_USER=${{ secrets.MYSQL_USER }}
          SQL_SERVER_PASSWORD=${{ secrets.MYSQL_PASSWORD }}
          SQL_SERVER_DATABASE=${{ secrets.MYSQL_DATABASE }}

          # LLM - OpenAI (Online Mode)
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL=gpt-4o
          LLM_TEMPERATURE=0.7
          LLM_MAX_TOKENS=2000

          # LLM - Local Servers (Offline Mode)
          LOCAL_LLM_URL_1=http://192.168.1.61/ai
          LOCAL_LLM_URL_2=http://192.168.1.62/ai

          # Default LLM Mode
          DEFAULT_LLM_MODE=auto

          # Timezone
          TZ=Asia/Tehran

          # Feature Flags
          ENABLE_GRAPH_RAG=true
          ENABLE_DOCUMENT_PROCESSING=true
          ENABLE_SQL_AUTH=true
          ENABLE_REDIS_CACHE=true
          EOF

          # Verify environment
          echo "=== Environment Variables Set ==="
          echo "NEO4J_PASSWORD: [SET]"
          echo "COCOINDEX_DB_PASSWORD: [SET]"
          [ ! -z "${{ secrets.MYSQL_HOST }}" ] && echo "MYSQL_HOST: [SET]" || echo "MYSQL: [NOT CONFIGURED]"
          [ ! -z "${{ secrets.OPENAI_API_KEY }}" ] && echo "OPENAI_API_KEY: [SET]" || echo "OPENAI: [NOT CONFIGURED]"
          echo "IMAGE_TAG: ${{ steps.tag.outputs.tag }}"

          # Stop running containers
          echo ""
          echo "=== Stopping running containers ==="
          docker compose down || true

          # Clean up old images
          echo ""
          echo "=== Cleaning up old images ==="
          docker image prune -f || true

          # Pull latest images
          echo ""
          echo "=== Pulling latest images ==="
          docker compose pull

          # Start services
          echo ""
          echo "=== Starting services ==="
          docker compose up -d

          # Wait for services
          echo ""
          echo "=== Waiting for services ==="
          for i in {1..60}; do
            echo "Check \$i/60..."
            if docker compose ps backend | grep -q "healthy"; then
              echo "✅ Backend is healthy"
              break
            fi
            sleep 5
          done

          # Show final status
          echo ""
          echo "=== Service Status ==="
          docker compose ps

          echo ""
          echo "========================================"
          echo "Release Deployment Complete!"
          echo "========================================"
          echo "Release Tag: ${{ steps.tag.outputs.tag }}"
          echo "Central Server: http://192.168.1.68"
          echo "========================================"

          ENDSSH

  deploy-llm-servers:
    name: Deploy to LLM Servers (1.61 & 1.62)
    runs-on: [self-hosted, simorgh-hub]
    needs: [build-llm-services]
    
    strategy:
      matrix:
        server:
          - host: 192.168.1.61
            name: llm-server-1
          - host: 192.168.1.62
            name: llm-server-2
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get tag name
        id: tag
        run: echo "tag=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ matrix.server.host }} >> ~/.ssh/known_hosts

      - name: Test SSH Connection
        run: |
          ssh -o StrictHostKeyChecking=no ubuntu@${{ matrix.server.host }} "echo 'SSH connection successful to ${{ matrix.server.name }}'"

      - name: Create deployment and model cache directories
        run: |
          ssh ubuntu@${{ matrix.server.host }} "mkdir -p ~/llm-deployment ~/models/huggingface"

      - name: Copy deployment files to remote server
        run: |
          scp -r $GITHUB_WORKSPACE/llms/* ubuntu@${{ matrix.server.host }}:~/llm-deployment/

      - name: Create .env file on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cat > ~/llm-deployment/.env << 'EOF'
          GITHUB_REGISTRY=${{ env.REGISTRY }}
          GITHUB_REPOSITORY_OWNER=${{ env.IMAGE_PREFIX }}
          IMAGE_TAG=${{ steps.tag.outputs.tag }}
          MODEL_CACHE_PATH=/home/ubuntu/models/huggingface
          EOF"

      - name: Verify environment on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && echo '=== Environment File ===' && cat .env"

      - name: Login to GHCR on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "echo '${{ secrets.GITHUB_TOKEN }}' | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin"

      - name: Stop running containers on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose down || true"

      - name: Clean up old images on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "docker image prune -f || true"

      - name: Pull latest images on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose pull"

      - name: Start services on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && docker compose up -d"

      - name: Monitor initializer progress
        run: |
          ssh ubuntu@${{ matrix.server.host }} "
            echo '=== Monitoring Model Initializer ==='
            timeout 1800 bash -c '
              while docker ps -a | grep -q model_initializer; do
                STATUS=\$(docker inspect model_initializer --format=\"{{.State.Status}}\" 2>/dev/null || echo \"not_found\")
                if [ \"\$STATUS\" = \"exited\" ]; then
                  EXIT_CODE=\$(docker inspect model_initializer --format=\"{{.State.ExitCode}}\" 2>/dev/null)
                  if [ \"\$EXIT_CODE\" = \"0\" ]; then
                    echo \"Model initializer completed successfully!\"
                    break
                  else
                    echo \"Model initializer failed with exit code \$EXIT_CODE\"
                    docker logs model_initializer --tail=50
                    exit 1
                  fi
                fi
                echo \"Initializer status: \$STATUS - waiting...\"
                sleep 10
              done
            ' || echo 'Warning: Initializer monitoring timed out'
          "

      - name: Wait for AI service to be healthy
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && timeout 180 bash -c 'until docker compose ps | grep -q \"healthy\"; do sleep 10; echo \"Waiting for services...\"; done' || echo 'Warning: Some services may not be healthy yet'"

      - name: Show service status on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment && echo '=== Docker Compose Status ===' && docker compose ps"

      - name: Show model cache info
        run: |
          ssh ubuntu@${{ matrix.server.host }} "echo '=== Model Cache Status ===' && du -sh ~/models/huggingface/* 2>/dev/null || echo 'No models cached yet'"

      - name: Check GPU availability on remote server
        run: |
          ssh ubuntu@${{ matrix.server.host }} "nvidia-smi || echo 'nvidia-smi not available'"

      - name: Show logs on failure
        if: failure()
        run: |
          ssh ubuntu@${{ matrix.server.host }} "cd ~/llm-deployment ; \
            echo '=== Docker Compose Status ===' ; docker compose ps -a ; echo ; \
            echo '=== Initializer Logs ===' ; docker logs model_initializer --tail=100 2>/dev/null || echo 'model_initializer container not found' ; echo ; \
            echo '=== AI Service Logs ===' ; docker logs ai_service --tail=100 ; echo ; \
            echo '=== GPU Monitor Logs ===' ; docker logs gpu_monitor --tail=50 2>/dev/null || echo 'gpu_monitor not started' ; echo ; \
            echo '=== Nginx Logs ===' ; docker logs nginx_ai --tail=50 2>/dev/null || echo 'nginx_ai not started'"

  health-check:
    name: Final Health Check
    runs-on: ubuntu-latest
    needs: [deploy-central-server]

    steps:
      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -p 2324 217.219.39.212 >> ~/.ssh/known_hosts

      - name: Run health checks
        run: |
          ssh -p 2324 -i ~/.ssh/deploy_key ${{ secrets.SSH_USER }}@217.219.39.212 << 'ENDSSH'
          echo "Waiting 30 seconds for application to fully start..."
          sleep 30

          echo "=== Checking Central Server (1.68) ==="
          for i in {1..10}; do
            echo "Attempt \$i/10..."
            if curl -f http://localhost/api/health; then
              echo ""
              echo "✅ Health check passed!"
              break
            else
              echo "⏳ Service not ready yet..."
              sleep 5
            fi
          done

          echo ""
          echo "=== Service Health Details ==="
          curl -s http://localhost/api/health | jq '.' || echo "Could not parse health response"

          echo ""
          echo "=== Checking LLM Servers ==="
          echo "LLM Server 1.61..."
          curl -f http://192.168.1.61/health || echo "Warning: LLM server 1.61 not reachable"
          echo ""
          echo "LLM Server 1.62..."
          curl -f http://192.168.1.62/health || echo "Warning: LLM server 1.62 not reachable"

          echo ""
          echo "================================"
          echo "Release Deployment Summary"
          echo "================================"
          echo "Release Tag: ${{ github.ref_name }}"
          echo "Central Server: http://192.168.1.68"
          echo "API Docs: http://192.168.1.68/api/docs"
          echo "Neo4j Browser: http://192.168.1.68:7474"
          echo "LLM Server 1: http://192.168.1.61"
          echo "LLM Server 2: http://192.168.1.62"
          echo "================================"

          ENDSSH