upstream ai_backend {
    server ai_service:9000;
    keepalive 32;
}

# Rate limiting - allow only central server
geo $limit {
    default 1;
    # Central server IP
    192.168.1.68 0;
    # Localhost
    127.0.0.1 0;
}

map $limit $limit_key {
    0 "";
    1 $binary_remote_addr;
}

limit_req_zone $limit_key zone=ai_limit:10m rate=10r/s;

server {
    listen 80;
    server_name _;

    # Security headers
    add_header X-Frame-Options "DENY" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # IP whitelist - only allow central server
    allow 192.168.1.68;  # Central server
    allow 127.0.0.1;     # Localhost
    deny all;

    # Override global client settings for this server
    client_max_body_size 100M;
    client_body_timeout 300s;

    # Health check endpoint (accessible to all allowed IPs)
    location /health {
        access_log off;
        proxy_pass http://ai_backend/health;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header Connection "";

        # Short timeout for health checks
        proxy_connect_timeout 10s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;
    }

    # All AI API traffic - proxy everything to ai_service
    # Removed specific /spec/ and /cable/ endpoints for simplicity
    location / {
        limit_req zone=ai_limit burst=20 nodelay;

        proxy_pass http://ai_backend/;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # SSE streaming support
        proxy_http_version 1.1;
        proxy_set_header Connection '';

        # Disable buffering for real-time streaming
        proxy_buffering off;
        proxy_cache off;
        proxy_request_buffering off;
        chunked_transfer_encoding on;

        add_header X-Accel-Buffering "no" always;
        add_header Cache-Control "no-cache" always;

        # Long timeouts for AI processing (30 minutes)
        proxy_connect_timeout 300s;
        proxy_send_timeout 1800s;
        proxy_read_timeout 1800s;
    }
}